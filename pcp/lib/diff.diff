30a31,33
> SWEEP_CALPARAM_FIELDS    = ["f0s", "i0", "q0", "didf0", "dqdf0", "didq2"]
> DERIVED_CALPARAM_FIELDS  = ["f0s", "didf_sumdidq2", "dqdf_sumdidq2", "i0_didf_sumdidq2", "q0_dqdf_sumdidq2"]
> 
52c55
<         _logger.warning( "Path doesn't exist." )
---
>         _logger.info( "Given path doesn't exist." )
129c132,134
<     return [os.path.basename(dirfile.fragment(i).name) for i in range(dirfile.nfragments)]
---
>     """Returns a dictionary of all fragments in a given dirfile. Syncs the dirfile before checking."""
>     dirfile.sync()
>     return { os.path.basename(dirfile.fragment(i).name) : i for i in range(dirfile.nfragments) }
153,154c158,159
<         return True, list_fragments_in_dirfile(dirfile).index(frag_name)
<     except ValueError:
---
>         return True, list_fragments_in_dirfile(dirfile)[frag_name]
>     except KeyError:
157,160c162,208
< def create_pcp_dirfile(roachid, dirfilename="", dirfile_type = "stream", tones=21, *dirfile_creation_flags, **kwargs):
<     """
<     High level function to create a new dirfile according to the pcp standards. This creates a format file with a number of tones
<     (to be standardised), and other packet information, read from roach_config (to be implmented).
---
> def check_dirfile_is_empty(dirfile):
>     """Returns True if dirfile is empty (len(INDEX) == 0), otherwise, False"""
>     # get the size of the INDEX field
>     return len( dirfile.getdata("INDEX") ) == 0
> 
> def get_fields_in_fragment(dirfile, frag_name, exclude_index=False):
>     """Convenience function to grab all fields from a given fragment. Couldn't find this function in pygetdata..."""
> 
>     isvalid, fragnum = check_fragment_valid(dirfile, frag_name)
> 
>     assert isvalid, "given fragment '{0}' doesn't appear to be a valid fragment.".format(frag_name)
> 
>     fields = dirfile.field_list()
> 
>     if exclude_index == True:
>         try:
>             fields.remove("INDEX")
>         except ValueError:
>             _logger.warning( "can't find index field in {0}".format(fields) )
> 
>     return [f for f in fields if dirfile.fragment_index(f) == fragnum]
> 
> def _fix_format_file(dirfile):
>     """Hack to bypass a bug found in pygetdata regarding the indexing of CARRAY fields in the definition of
>     derived fields. This identifies fields that use <idx> in the defintion of the derived field, and assuming that
>     the order of the fields in the dirfile maps onto the order of the CARRAY indexing, replaces the <0> with the
>     corresponding index. Assumes field list from dirfile is sorted (which it should be...) """
> 
>     fname = dirfile.name
> 
>     isvalid, fragnum = check_fragment_valid(dirfile, "derived")
>     fmtfname = dirfile.fragment(fragnum)
> 
>     # sync dirfile before going any further
>     dirfile.sync()
> 
>     # get the fields for the derived fragment
>     dervied_fields = get_fields_in_fragment(dirfile, "derived")
> 
>     with open(dirfile.fragment(fragnum).name, 'r+') as fin:
>         lines = fin.readlines()
>         #lines_to_change = [l for l in fin.readlines() if "<" in l]
> 
>         idx = 0
>         prev_field_name = next(line for line in lines if "<" in line).split(" ")[0]
> 
>         for i, line in enumerate(lines):
162,163c210,217
<     If no dirfilename is given, or if dirfilename is a path and not a valid dirfile, then a new dirfile will be created using
<     the default filename format.
---
>             if "<" in line:
>                 field_name = line.split(" ")[0]
>                 if field_name == prev_field_name:
>                     pass
>                 else:
>                     prev_field_name = field_name
>                     idx += 1
>                 lines[i] = line.replace("<0>","<{0}>".format(idx) )
165c219,221
<     If a valid dirfile is given, a warning will be given and it will be passed through.
---
>         # write new lines back to the format file
>         fin.seek(0)
>         fin.writelines(lines)
167,168c223,227
<     Valid kwargs:
<         - datatag; string to add to file path prepended by a leading underscore. Only applies to new filenames. Default is empty string.
---
>     dirfile.close()
> 
>     return _gd.dirfile(fname, dirfile.flags)
> 
> def create_pcp_dirfile(roachid, dfname="", dftype = "stream", tonenames = [], *df_creation_flags, **kwargs):
170,171c229,262
<     # check that the input is a string
<     assert type(dirfilename) == str
---
>     High level function to create a new dirfile according to the pcp standards. This creates a format file with a number of tones,
>     and other packet information.
> 
>     Parameters
>     ============
>     dfname: str
>         Path to a dirfile, or directory in which to create a new dirfile. If no dirfilename is given (or ""), or if dirfilename
>         is a valid path but not a valid dirfile, then a new dirfile will be created in this directory using the default filename
>         format given in general_config['default_datafilename_format'].
> 
>         If dfname a valid dirfile path is given and exclusive = False, the dirfile will be opened and returned. If exclusive = True
>         (default) then an error is raised.
> 
>     dftype: str
>         Currently, one of ["stream", "sweep"]. Anything else raises an error.
> 
>     tones: list
>         A list of field names that will be used as the dirfile fields.
> 
>     df_creation_flags:
>         Bit-wise or'd args that are passed to gd.dirfile().
> 
>     Valid kwargs
>     ============
>     filename_suffix: str (default: "")
>         string to add to the end of the file path, prepended by a leading underscore. This is added before checking whether
>         the resulting path exists.
> 
>     exclusive: bool (default: True)
>         Switch to handle existing dirfiles. If True, an error is raised if the given path is an existing dirfile.
>         If False, this function opens and returns the dirfile object to continued writing/processing.
> 
>     array_size: int (default: 101)
>         Used for sweep dirfiles only. Sets the array size for the sweep fields.
173c264,265
<     assert dirfile_type in ["stream", "sweep"]
---
>     inc_derived_fields: bool (default: False)
>         Switch to include the derived fields relevant to the type of the dirfile requested.
175,176c267,281
<     # handle kwargs
<     filename_suffix = kwargs.pop("filename_suffix", "") # str to add to file path (only applies to new filenames)
---
>     Returns
>     ============
>     dirfile: pygetdata.dirfile
>         Initialised and opened pygetdata dirfile object of requested type.
> 
>     TODO:
>      - handle empty string with filename_suffix
> 
>     """
>     # preliminary checks
>     assert type(dfname) == str
>     assert dftype in ["stream", "sweep"]
> 
>     # --- handle kwargs ---
>     filename_suffix = kwargs.pop("filename_suffix", "") # str to add to file path
179c284,290
<     array_size = kwargs.pop("array_size", 101) # default size used for sweep file creation
---
>     dfname = dfname.rstrip("/") + filename_suffix
> 
>     _logger.debug("dirfile path to write: {0}".format(dfname))
> 
>     exclusive          = kwargs.pop("exclusive", True) # str to add to file path (only applies to new filenames)
>     array_size         = kwargs.pop("array_size", 101) # default size used for sweep file creation
>     inc_derived_fields = kwargs.pop("inc_derived_fields", True) # option to include derived fields to dirfile
182a294
>     # ------
185c297
<     dirfileflagint = np.bitwise_or.reduce(dirfileflags) if dirfile_creation_flags \
---
>     dfflagint = np.bitwise_or.reduce(df_creation_flags) if df_creation_flags \
188,190c300,306
<     if is_path_a_dirfile(dirfilename):
<         _logger.info( "It looks like {0} is a valid dirfile. Opening and returning dirfile.".format(dirfilename) )
<         return _gd.dirfile(dirfilename, _gd.RDWR|_gd.UNENCODED)
---
>     if is_path_a_dirfile(dfname):
>         _logger.debug("{0} is a valid dirifle".format(dfname))
>         if exclusive:
>             raise IOError, "{0} exists and exclusive = True. Use exclusive = False to return this dirfile".format(dfname)
>         else:
>             _logger.info( "It looks like {0} is a valid dirfile. Opening and returning dirfile.".format(dfname) )
>             return _gd.dirfile(dfname, _gd.RDWR|_gd.UNENCODED)
193,195c309,311
<     elif os.path.exists(dirfilename) or dirfilename == "":
<         dirfilename = os.path.join( dirfilename, time.strftime(general_config['default_datafilename_format']) + filename_suffix )
< 
---
>     elif os.path.exists(dfname) or dfname == "":
>         dfname = os.path.join( dfname, time.strftime(general_config['default_datafilename_format']) + filename_suffix )
>         _logger.debug("path exists; assume this is a directory in which to create the new dirfile".format(dfname))
201c317
<     dirfile = _gd.dirfile(dirfilename, dirfileflagint)
---
>     dirfile = _gd.dirfile(dfname, dfflagint)
205,206c321,324
<     if dirfile_type == "stream":
<         dirfile = generate_main_rawfields(dirfile, roachid, tones, fragnum = 0)#, field_suffix = field_suffix)
---
>     if dftype == "stream":
>         dirfile = generate_main_rawfields(dirfile, roachid, tonenames, fragnum = 0)#, field_suffix = field_suffix)
>         if inc_derived_fields: # true by default
>             dirfile = generate_main_derivedfields(dirfile, tonenames)
208,209c326,327
<     elif dirfile_type == "sweep":
<         dirfile = generate_sweep_fields(dirfile, tones, array_size = array_size)#, field_suffix = field_suffix)
---
>     elif dftype == "sweep":
>         dirfile = generate_sweep_fields(dirfile, tonenames, array_size = array_size)#, field_suffix = field_suffix)
237c355
< def generate_main_rawfields(dirfile, roachid, tones, fragnum=0 ):#, field_suffix = ""):
---
> def generate_main_rawfields(dirfile, roachid, tonenames, fragnum=0 ):#, field_suffix = ""):
242c360
<         print "given dirfile is of type {0}, and not a valid dirfile. Nothing done.".format(type(dirfile))
---
>         _logger.error( "given dirfile is of type {0}, and not a valid dirfile. Nothing done.".format(type(dirfile)) )
245c363
<         print "Unrecognised roachid = {0}".format(roachid)
---
>         _logger.error( "Unrecognised roachid = {0}".format(roachid) )
258c376,379
<     aux_entries_to_write = []
---
>     # write the python_timestamp field manually
>     aux_entries_to_write = [ _gd.entry( _GDENTRYMAP[ firmware_dict["packet_structure"]['python_timestamp'][0] ], namespace + 'python_timestamp', \
>                                             fragnum, \
>                                             (_GDDATAMAP[ firmware_dict["packet_structure"]['python_timestamp'][1] ], 1) ) ]
268c389
<     kid_fields_I, kid_fields_Q = toneslist.gen_tone_iq_fields(tones, namespace=namespace) #, field_suffix = field_suffix)
---
>     kid_fields_I, kid_fields_Q = toneslist.gen_tone_iq_fields(tonenames, namespace=namespace) #, field_suffix = field_suffix)
273,274c394,399
<     # add all entries into format file
<     for entry in aux_entries_to_write + kid_entries_to_write:
---
>     # generate entries for bbfreqs and lofreq
>     lofreq_entry   = _gd.entry(_gd.CONST_ENTRY, "lofreq",   fragnum, (_gd.FLOAT64, ) )
>     bbfreq_entry   = _gd.entry(_gd.CARRAY_ENTRY, "bbfreqs", fragnum, (_gd.FLOAT64, len(tonenames)) )
>     tonename_entry = _gd.entry(_gd.SARRAY_ENTRY, "tonenames", fragnum, (len(tonenames), ) )
> 
>     for entry in aux_entries_to_write + kid_entries_to_write + [lofreq_entry, bbfreq_entry, tonename_entry]:
280c405,448
< def generate_sweep_fields(dirfile, tones, array_size = 501 ):#, field_suffix=""):
---
> def generate_main_derivedfields(dirfile, field_names):
>     """Generate the calibration fragment for the streaming dirfiles. To calculate the derived fields such as dff0,
>     the LINCOM entries require combinations of the parameters from the sweep, defined in
>     pcp.lib.lib_dirfiles.SWEEP_CALPARAM_FIELDS. """
>     # requires calibration data - this can be written to the dirfile later
>     calns = ""
> 
>     calfrag = dirfile.include("calibration", namespace = calns, flags = _gd.CREAT|_gd.EXCL|_gd.RDWR)
>     nfields = len(field_names)
> 
>     cal_entries = [_gd.entry(_gd.CARRAY_ENTRY, calfield, calfrag, (_gd.FLOAT64, nfields) ) for calfield in DERIVED_CALPARAM_FIELDS]
>     # create a fragment for the derived fields
>     derivedfrag = dirfile.include("derived", flags = _gd.CREAT|_gd.EXCL|_gd.RDWR )
> 
>     # create the entries for the derived fields for a stream file
>     zentries, magzentries, angzentries, dfentries, dff0entries = [],[],[],[],[]
>     for idx, field_name in enumerate( sorted( field_names ) ):
>         # complex combination of i and q
>         zentries.append( _gd.entry(_gd.LINCOM_ENTRY, field_name + "_z", derivedfrag, ( (field_name + "_I", field_name + "_Q" ), (1,1j), (0,0) ) ) )
>         # raw amplitude
>         magzentries.append ( _gd.entry(_gd.PHASE_ENTRY, field_name + '_magz', derivedfrag, ( (field_name + '_z.m'), 0) ) )
>         # raw phase
>         angzentries.append ( _gd.entry(_gd.PHASE_ENTRY, field_name + '_angz', derivedfrag, ( (field_name + '_z.a'), 0) ) )
>         # fraction frequency shift
>         dfentries.append ( _gd.entry(_gd.LINCOM_ENTRY, field_name + '_df', derivedfrag, ( (field_name + "_I", field_name + "_Q" ), \
>                                                                                             ("didf_sumdidq2", "dqdf_sumdidq2"),\
>                                                                                             ("i0_didf_sumdidq2", "q0_dqdf_sumdidq2") ) ) )
> 
>         #dff0entries.append ( _gd.entry(_gd.DIVIDE_ENTRY, field_name + '_dff0', derivedfrag, ( (field_name + "_df", "f0s"]) ) ) ) )
> 
>         derived_entries = zentries + magzentries + angzentries + dfentries# + dff0entries
> 
>     # add all the entries to the dirfile
>     map(dirfile.add, cal_entries + derived_entries)
> 
>     dirfile.flush()
>     # hack to fix the derived format file from a bug in pygetdata
>     dfname = dirfile.name
>     _fix_format_file(dirfile) # <- this makes the dirfile invalid. so, close and reopen
>     dirfile.close()
> 
>     return _gd.dirfile(dfname, _gd.EXCL|_gd.RDWR)
> 
> def generate_sweep_fields(dirfile, tonenames, array_size = 501, fragnum = 0 ):#, field_suffix=""):
286c454
<     swp_fields = toneslist.get_tone_fields( tones )
---
>     swp_fields = toneslist.get_tone_fields( tonenames )
291,293c459,466
<     sweep_entry_freq       = [ _gd.entry(_gd.CARRAY_ENTRY, "sweep." + "lo_freqs", 0, (_gd.FLOAT64,   array_size)) ]
<     sweep_entry_bb         = [ _gd.entry(_gd.CARRAY_ENTRY, "sweep." + "bb_freqs", 0, (_gd.FLOAT64,   len(tones))) ]
<     sweep_entries_to_write = [ _gd.entry(_gd.CARRAY_ENTRY, "sweep." + field_name, 0, (_gd.COMPLEX64, array_size)) for field_name in swp_fields ]
---
>     # sweep_entry_freq       = [ _gd.entry(_gd.CARRAY_ENTRY, "sweep." + "lo_freqs", 0, (_gd.FLOAT64,   array_size)) ]
>     # sweep_entry_bb         = [ _gd.entry(_gd.CARRAY_ENTRY, "sweep." + "bb_freqs", 0, (_gd.FLOAT64,   len(tones))) ]
>     # sweep_entries_to_write = [ _gd.entry(_gd.CARRAY_ENTRY, "sweep." + field_name, 0, (_gd.COMPLEX64, array_size)) for field_name in swp_fields ]
> 
>     sweep_entry_freq       = [ _gd.entry(_gd.CARRAY_ENTRY, "lo_freqs",  fragnum, (_gd.FLOAT64,   array_size)) ]
>     sweep_entry_bb         = [ _gd.entry(_gd.CARRAY_ENTRY, "bb_freqs",  fragnum, (_gd.FLOAT64,   len(tonenames))) ]
>     sweep_entry_tonenames  = [ _gd.entry(_gd.SARRAY_ENTRY, "tonenames", fragnum, (len(tonenames),)) ]
>     sweep_entries_to_write = [ _gd.entry(_gd.CARRAY_ENTRY, field_name,  fragnum, (_gd.COMPLEX64, array_size)) for field_name in swp_fields ]
297c470
<     map(dirfile.add, sweep_entry_freq + sweep_entry_bb + sweep_entries_to_write)
---
>     map(dirfile.add, sweep_entry_freq + sweep_entry_bb + sweep_entry_tonenames + sweep_entries_to_write)
300,302c473
< 
<     # constants for F0s, i0, q0, didf0, dqdf0, didq0
<     cal_data_fields = ["f0s", "i0", "q0", "didf0", "dqdf0", "didq2"]
---
>     # constants for F0s, i0, q0, didf0, dqdf0, didq0 -
304c475,478
<     # constants for centres and rotation for phase (just start with df)
---
>     # TODO constants for centres and rotation for phase (just start with df)
> 
>     caldata_frag  = dirfile.include("caldata",  namespace = 'caldata',  flags = _gd.CREAT|_gd.EXCL)
>     calparam_frag = dirfile.include("calparam", namespace = 'calparam', flags = _gd.CREAT|_gd.EXCL)
306c480,481
<     cal_fragment = dirfile.include("calibration", flags = _gd.CREAT|_gd.EXCL)
---
>     caldata_ns  = dirfile.fragment(caldata_frag).namespace
>     calparam_ns = dirfile.fragment(calparam_frag).namespace
309,310c484,485
<     cal_param_entries        = [ _gd.entry(_gd.CARRAY_ENTRY, "cal."     + field_name, cal_fragment, (_gd.FLOAT64, len(tones)) )  for field_name in cal_data_fields]
<     caldata_entries_to_write = [ _gd.entry(_gd.CARRAY_ENTRY, "caldata." + field_name, cal_fragment, (_gd.COMPLEX64, array_size)) for field_name in swp_fields ]
---
>     # i0s, q0s, didf0s ...etc for all the tones
>     calparam_entries = [ _gd.entry(_gd.CARRAY_ENTRY, ".".join((calparam_ns, field_name)), calparam_frag, (_gd.FLOAT64, len(tonenames)) )  for field_name in SWEEP_CALPARAM_FIELDS]
312c487,488
<     _logger.debug("generating new sweep cal fields: {0}".format(cal_param_entries + caldata_entries_to_write) )
---
>     # didf, dqdf, didq...etc for each tone - maybe not needed?
>     caldata_entries = [ _gd.entry(_gd.CARRAY_ENTRY, ".".join((caldata_ns, field_name)), caldata_frag, (_gd.COMPLEX64, array_size)) for field_name in swp_fields ]
314c490,492
<     map(dirfile.add, cal_param_entries + caldata_entries_to_write)
---
>     _logger.debug("generating new sweep cal fields: {0}".format(calparam_entries + caldata_entries) )
> 
>     map(dirfile.add, calparam_entries + caldata_entries)
344,345d521
< def generate_main_derivedfields(dirfile):
<     pass
347,350d522
< def check_dirfile_is_empty(dirfile):
<     """Returns True if dirfile is empty (len(INDEX) == 0), otherwise, False"""
<     # get the size of the INDEX field
<     return len( dirfile.getdata("INDEX") ) == 0
352c524
< def add_subdirfile_to_existing_dirfile(subdirfile, dirfile, namespace = "", overwrite=False):
---
> def add_subdirfile_to_existing_dirfile(subdirfile, dirfile, namespace = "", field_suffix = "", overwrite=False, symlink=True):
362a535,536
>     # ensure that the namespace is not empty to avoid duplicating field names
>     namespace = "subdir" if not namespace else namespace
368c542
<         print "Invlaid dirfile. Make sure the dirfile is open and exists. Nothing done. Returning. "
---
>         _logger.error( "Invlaid dirfile. Make sure the dirfile is open and exists. Nothing done. Returning. " )
371c545
<         print "inputs do not appear to be dirfiles"
---
>         _logger.error( "inputs do not appear to be dirfiles" )
378c552
<             print "warning: path to new subdir already exists. Overwriting"
---
>             _logger.warning( "path to new subdir already exists. Overwriting..." )
381c555
<             print "Not overwriting. Returning."
---
>             _logger.warning(  "Not overwriting. Returning." )
387c561,564
<         shutil.copytree(subdirfile.name, new_subdirfile_path)
---
>         if symlink:
>             os.symlink(subdirfile.name, new_subdirfile_path)
>         else:
>             shutil.copytree(subdirfile.name, new_subdirfile_path)
390c567
<         print "Copy unsuccesful - nothing done; error:", err
---
>         _logger.error( "Copy unsuccesful - nothing done; error: {0}".format( err ) )
393c570
<     # add a the subdrifile as a new fragment
---
>     # add a the subdrifile as a new fragment (# NOTE: namespace should not be an empty string)
395,396c572,575
<     newfrag = dirfile.include(os.path.join(os.path.basename(subdirfile.name), "format"), namespace = namespace, flags = _gd.EXCL|_gd.RDWR)
<     # could change above to df.fragment(0).name
---
>     newfrag = dirfile.include(os.path.join(os.path.basename(subdirfile.name), "format"),\
>                                 namespace = namespace,\
>                                 suffix    = field_suffix,\
>                                 flags     = _gd.EXCL|_gd.RDWR)
401,424d579
< def write_sweep_cal_params(dirfile, cal_params, cal_data_dict):
< 
<     assert is_dirfile_valid(dirfile)
< 
<     assert isinstance(cal_data_dict, dict), "cal data is required to be in a dictionary with tonename: caldata as key: value"
<     # cal params = (sweep_f[idxs], sweep_i[idxs], sweep_q[idxs], didf[idxs], dqdf[idxs])
<     # cal_data  = (didf, dqdf, didq2)
< 
<     # check that sweep cal_fragment is available
<     is_frag_valid, calfrag = check_fragment_valid(dirfile, "calibration")
<     if not is_frag_valid:
<         _logger.warning("there doesn't appear to be a claibration fragment. Calibration parameters not written.")
<         return
< 
<     cal_param_fields = ["f0s", "i0", "q0", "didf0", "dqdf0", "didq2"]
<     cal_data_fields = ["didf", "dqdf", "didf2"] # dictionaries
< 
<     for cal_param_field, cal_param in zip(cal_param_fields, cal_params):
<         dirfile.put_carray("cal." + cal_param_field, cal_param)
< 
<     for tone_name, cal_data in cal_data_dict.items():
<         dirfile.put_carray("caldata." + tone_name, cal_data)
< 
<     dirfile.flush()
446,498d600
< def create_sweep_derived_fields(dirfile, f_tone):
< 
<     calfrag = dirfile.include("calibration", flags = _gd.EXCL|_gd.RDWR )
< 
<     for chan in channels:
<         dirfile.add( _gd.entry( _gd.CONST_ENTRY,'_cal_tone_freq_%04d'%chan,calfrag,(_gd.FLOAT64,) ) )
<         dirfile.put_constant('_cal_tone_freq_%04d'%chan, f_tone[chan])
< 
<         #i-i0 q-q0
<         dirfile.add(_gd.entry(_gd.LINCOM_ENTRY, '_cal_i_sub_i0_%04d'%chan, calfrag, (("I%04d"%chan,),(1,),(-1*i_tone,))))
<         dirfile.add(_gd.entry(_gd.LINCOM_ENTRY, '_cal_q_sub_q0_%04d'%chan, calfrag, (("Q%04d"%chan,),(1,),(-1*q_tone,))))
< 
<         #Complex values
<         dirfile.add(_gd.entry(_gd.LINCOM_ENTRY,'_cal_complex_%04d'%chan,calfrag, (("I%04d"%chan,"Q%04d"%chan),(1,1j),(0,0))))
< 
<         #Amplitude
<         dirfile.add(_gd.entry(_gd.PHASE_ENTRY,'amplitude_%04d'%chan,calfrag, (('_cal_complex_%04d.m'%chan),0)))
< 
<         #Phase
<         dirfile.add(_gd.entry(_gd.LINCOM_ENTRY,'phase_raw_%04d'%chan,calfrag,
<         (('_cal_complex_%04d.a'%chan,),(1,1j),(0,))))
< 
<         #Complex_centered:
<         dirfile.add(_gd.entry(_gd.LINCOM_ENTRY,'_cal_centred_%04d'%chan,calfrag,
<         (("_cal_complex_%04d"%chan,),(1,),(-c[0]-1j*c[1],))))
< 
<         #Complex_rotated
<         dirfile.add(_gd.entry(_gd.LINCOM_ENTRY,'_cal_rotated_%04d'%chan,calfrag,
<         (("_cal_centred_%04d"%chan,),(np.exp(-1j*phi_tone),),(0,))))
< 
<         #Phase
<         dirfile.add(_gd.entry(_gd.LINCOM_ENTRY,'phase_rotated_%04d'%chan,calfrag,
<         (('_cal_rotated_%04d.a'%chan,),(1,),(0,))))
< 
<         #df = ((i[0]-i)(di/df) + (q[0]-q)(dq/df) ) / ((di/df)**2 + (dq/df)**2)
<         dirfile.add(_gd.entry(_gd.CONST_ENTRY,'_cal_didf_mult_%04d'%chan,calfrag,(_gd.FLOAT64,)))
<         dirfile.add(_gd.entry(_gd.CONST_ENTRY,'_cal_dqdf_mult_%04d'%chan,calfrag,(_gd.FLOAT64,)))
<         dirfile.put_constant('_cal_didf_mult_%04d'%chan,didf_tone/(didf_tone**2+dqdf_tone**2))
<         dirfile.put_constant('_cal_dqdf_mult_%04d'%chan,dqdf_tone/(didf_tone**2+dqdf_tone**2))
<         dirfile.add(_gd.entry(_gd.LINCOM_ENTRY,'_cal_i0_sub_i_%04d'%chan,calfrag,
<         (("I%04d"%chan,),(-1,),(i_tone,))))
<         dirfile.add(_gd.entry(_gd.LINCOM_ENTRY,'_cal_q0_sub_q_%04d'%chan,calfrag,
<         (("Q%04d"%chan,),(-1,),(q_tone,))))
<         dirfile.add(_gd.entry(_gd.LINCOM_ENTRY, 'delta_f_%04d'%chan, calfrag,
<         (("_cal_i0_sub_i_%04d"%chan,"_cal_q0_sub_q_%04d"%chan),
<         ("_cal_didf_mult_%04d"%chan,"_cal_dqdf_mult_%04d"%chan),
<         (0,0))))
< 
<         #x = df/f0
<         dirfile.add(_gd.entry(_gd.LINCOM_ENTRY,'x_%04d'%chan,calfrag,
<         (('delta_f_%04d'%chan,),(1./f_tone[chan],),(0,))))
< 
< 
523c625
< def get_data_from_datapacket_dict(datapacket_dict, field_name):
---
> def get_auxdata_from_datapacket_dict(datapacket_dict, field_name):
530,531c632,633
<     """Function to act as the consumer, that will be given a 2d array of data
<     comprising multiple packets, and will write the data to disk.
---
>     """Function to act as the consumer, that takes the datapacket_dict with
>     data from multiple packets, and write that data to disk.
541c643
<     assert len(field_list) <= len(datapacket_dict)
---
>     #assert len(field_list) <= len(datapacket_dict)
549a652
>     # write the data
551,554d653
<         #dirfile.putdata(field_name, get_data_from_datapacket_dict(datapacket_dict, field_name), first_sample = currentsize ) #+ 1)
<         
<         data_to_write = get_data_from_datapacket_dict(datapacket_dict, field_name)
<         dirfile.putdata(field_name, data_to_write, first_sample = currentsize )
556c655,667
<     #dirfile.flush()
---
>         if field_name in datapacket_dict['aux_fields'].keys():
>             dirfile.putdata(field_name, get_auxdata_from_datapacket_dict(datapacket_dict['aux_fields'], field_name), first_sample = currentsize ) #+ 1)
> 
>         elif field_name in datapacket_dict['tone_fields'].keys():
>             toneidx = datapacket_dict['tone_fields'][field_name][-1]
>             #print toneidx, field_name
>             dirfile.putdata( field_name, datapacket_dict['tone_data'][toneidx], first_sample = currentsize )
> 
>         elif field_name in ['python_timestamp']:
>             data = datapacket_dict[field_name][-1]
>             dirfile.putdata( 'python_timestamp',
>                             np.ascontiguousarray( [data.pop(0) for i in range(len(data))] ).flatten(),
>                             first_sample = currentsize )
558c669,674
< def generate_sweep_dirfile( roachid, dirfilename, lo_frequencies, bb_frequencies, complex_sweep_data_dict ):#, field_suffix = "" ):
---
>         else:
>             raise TypeError, "warning, unknown field name {0}".format(field_name)
> 
>     dirfile.flush()
> 
> def generate_sweep_dirfile( roachid, dirfilename, tonenames, numpoints = 501 ):
566,569c682,684
<     tone_names       = complex_sweep_data_dict.keys()#len(complex_sweep_data_dict)
<     num_sweep_points = len(lo_frequencies)
<     _logger.debug( "tone names used for sweep fields: {0}".format( tone_names ) )
<     _logger.debug( "number of sweep points {0}".format( num_sweep_points ) )
---
>     #tone_names       = complex_sweep_data_dict.keys()#len(complex_sweep_data_dict)
>     _logger.debug( "tone names used for sweep fields: {0}".format( tonenames ) )
>     _logger.debug( "number of sweep points {0}".format( numpoints ) )
572c687,693
<     sweep_dirfile = create_pcp_dirfile(roachid, dirfilename, dirfile_type = "sweep", tones = tone_names, array_size = num_sweep_points, filename_suffix = "sweep")
---
>     sweep_dirfile = create_pcp_dirfile(roachid, dirfilename,
>                                         dftype          = "sweep",
>                                         tonenames       = tonenames,
>                                         array_size      = numpoints,
>                                         filename_suffix = "sweep",
>                                         exclusive       = True ) #<-- makes sure that the sweep files are not overwritten/ appended to
>     return sweep_dirfile
574,575c695,706
<     sweep_dirfile.put_carray("sweep." + "bb_freqs", bb_frequencies)
<     sweep_dirfile.put_carray("sweep." + "lo_freqs", lo_frequencies)
---
> def write_sweepdata_to_sweepdirfile(sweep_dirfile, bbfreqs, lofreqs, tonenames, complex_sweep_data_dict):
>     """Add sweep data to a pcp sweep dirfile.
>     Requires:
> 
>         bbfreqs - array of baseband frequencies
>         lofreqs - array of lo frequencies
>         complex_sweep_data_dict - dictionary of tonename: complex data
> 
>     """
>     sweep_dirfile.put_sarray("tonenames", list(tonenames) )
>     sweep_dirfile.put_carray("bb_freqs", bbfreqs)
>     sweep_dirfile.put_carray("lo_freqs", lofreqs)
578c709
<         sweep_dirfile.put_carray("sweep." + field_name, sweep_data)
---
>         sweep_dirfile.put_carray(field_name, sweep_data)
624a756,783
> def append_dirfile_to_sourcefile(srcfile, dirfilename, timespan = 120.):
>     """
>     Function to append a dirfile to a source file list for easy reading in KST. Time span, in minutes, is the
>     length of time for which the dirfiles remain in the sourcefile
>     """
> 
>     assert not srcfile.closed, "source file appears to be closed - check again"
> 
>     # read sourcefile contents
>     srcfile.seek(0)
>     dirfilelist = np.array( [f.strip() for f in srcfile.readlines()] )
> 
>     # get last modified timestamps for current files
>     modtimes = np.array( [os.path.getmtime(df) for df in dirfilelist] )
> 
>     # choose only where last modified times are greater than timespan
>     dirfilelist = dirfilelist[ modtimes > time.time() - timespan * 60. ]
>     # append new file to the list
>     print dirfilelist
>     dirfilelist = np.append( dirfilelist, dirfilename )
>     print dirfilelist
> 
>     # write to file (adding newlines)
>     srcfile.seek(0)
>     srcfile.writelines( np.char.add( dirfilelist, '\n' ) )
>     srcfile.truncate()
>     srcfile.flush()
> 
681a841,893
> 
> # old cardiff code used to write derived fields
> # def create_sweep_derived_fields(dirfile, f_tone):
> #
> #     calfrag = dirfile.include("calibration", flags = _gd.EXCL|_gd.RDWR )
> #
> #     for chan in channels:
> #         dirfile.add( _gd.entry( _gd.CONST_ENTRY,'_cal_tone_freq_%04d'%chan,calfrag,(_gd.FLOAT64,) ) )
> #         dirfile.put_constant('_cal_tone_freq_%04d'%chan, f_tone[chan])
> #
> #         #i-i0 q-q0
> #         dirfile.add(_gd.entry(_gd.LINCOM_ENTRY, '_cal_i_sub_i0_%04d'%chan, calfrag, (("I%04d"%chan,),(1,),(-1*i_tone,))))
> #         dirfile.add(_gd.entry(_gd.LINCOM_ENTRY, '_cal_q_sub_q0_%04d'%chan, calfrag, (("Q%04d"%chan,),(1,),(-1*q_tone,))))
> #
> #         #Complex values
> #         dirfile.add(_gd.entry(_gd.LINCOM_ENTRY,'_cal_complex_%04d'%chan,calfrag, (("I%04d"%chan,"Q%04d"%chan),(1,1j),(0,0))))
> #
> #         #Amplitude
> #         dirfile.add(_gd.entry(_gd.PHASE_ENTRY,'amplitude_%04d'%chan,calfrag, (('_cal_complex_%04d.m'%chan),0)))
> #
> #         #Phase
> #         dirfile.add(_gd.entry(_gd.LINCOM_ENTRY,'phase_raw_%04d'%chan,calfrag,
> #         (('_cal_complex_%04d.a'%chan,),(1,1j),(0,))))
> #
> #         #Complex_centered:
> #         dirfile.add(_gd.entry(_gd.LINCOM_ENTRY,'_cal_centred_%04d'%chan,calfrag,
> #         (("_cal_complex_%04d"%chan,),(1,),(-c[0]-1j*c[1],))))
> #
> #         #Complex_rotated
> #         dirfile.add(_gd.entry(_gd.LINCOM_ENTRY,'_cal_rotated_%04d'%chan,calfrag,
> #         (("_cal_centred_%04d"%chan,),(np.exp(-1j*phi_tone),),(0,))))
> #
> #         #Phase
> #         dirfile.add(_gd.entry(_gd.LINCOM_ENTRY,'phase_rotated_%04d'%chan,calfrag,
> #         (('_cal_rotated_%04d.a'%chan,),(1,),(0,))))
> #
> #         #df = ((i[0]-i)(di/df) + (q[0]-q)(dq/df) ) / ((di/df)**2 + (dq/df)**2)
> #         dirfile.add(_gd.entry(_gd.CONST_ENTRY,'_cal_didf_mult_%04d'%chan,calfrag,(_gd.FLOAT64,)))
> #         dirfile.add(_gd.entry(_gd.CONST_ENTRY,'_cal_dqdf_mult_%04d'%chan,calfrag,(_gd.FLOAT64,)))
> #         dirfile.put_constant('_cal_didf_mult_%04d'%chan,didf_tone/(didf_tone**2+dqdf_tone**2))
> #         dirfile.put_constant('_cal_dqdf_mult_%04d'%chan,dqdf_tone/(didf_tone**2+dqdf_tone**2))
> #         dirfile.add(_gd.entry(_gd.LINCOM_ENTRY,'_cal_i0_sub_i_%04d'%chan,calfrag,
> #         (("I%04d"%chan,),(-1,),(i_tone,))))
> #         dirfile.add(_gd.entry(_gd.LINCOM_ENTRY,'_cal_q0_sub_q_%04d'%chan,calfrag,
> #         (("Q%04d"%chan,),(-1,),(q_tone,))))
> #         dirfile.add(_gd.entry(_gd.LINCOM_ENTRY, 'delta_f_%04d'%chan, calfrag,
> #         (("_cal_i0_sub_i_%04d"%chan,"_cal_q0_sub_q_%04d"%chan),
> #         ("_cal_didf_mult_%04d"%chan,"_cal_dqdf_mult_%04d"%chan),
> #         (0,0))))
> #
> #         #x = df/f0
> #         dirfile.add(_gd.entry(_gd.LINCOM_ENTRY,'x_%04d'%chan,calfrag,
> #         (('delta_f_%04d'%chan,),(1./f_tone[chan],),(0,))))
\ No newline at end of file
